---
title: "Simple BEMC"
author: "Eric Kernfeld"
date: "March 17, 2016"
output: html_document
---

```{r}
rm(list = ls())
```

##Simple BEMC

Code within this document implements a simple version of BEMC. It supports 

- only parameter spaces equal to $\mathbb{R}^D$
- only MVN basis functions
- only one dimension right now

The basic data structure throughout the implementation is a basis: a list of multivariate Gaussians with means, covariances, Cholesky factors, precisions, pairwise $L_2$ inner products of basis functions, matrices describing the action of the M-H sampler, and coefficients of the estimated target density.

```{r}
init_single_scale_basis = function(range, num_elements, tightness = 2){  
  default_var = ((range[2] - range[1]) / (tightness * num_elements))^2
  basis = list(means       = as.list(ppoints(num_elements) * (range[2] - range[1]) + range[1]), 
               covariances = as.list(rep(default_var,       length.out = num_elements)))
  basis$length = num_elements
  return(basis)
}

concat_basis_skeletons = function(skeleton_list){
  basis = list(means = list(), covariances = list(), length = 0)
  for(bi in skeleton_list){
    basis$means       = append(basis$means,       bi$means)
    basis$covariances = append(basis$covariances, bi$covariances)
    basis$length = basis$length + bi$length
  }
  return(basis)
}

init_multiscale_basis = function(range, num_layers){
  bases = list()
  for(i in 1:num_layers){
    bases = append(bases, list( init_single_scale_basis( range, num_elements = 2^(i-1) ) ) )
  }
  basis = concat_basis_skeletons(bases)
  return(basis)
}

prepare_basis = function(dimension = 1, 
                         num_elements = 50, 
                         range = c(-5, 5), 
                         num_neighbors = 5,
                         multiscale = FALSE,
                         num_layers = 5){
  assertthat::assert_that(dimension==1) #Don't have a default initialization yet
  if(multiscale){
    warning("Constructing multiscale basis. Ignoring num_elements argument")
    basis = init_multiscale_basis(range, num_layers)
  } else {
    warning("Constructing single scale basis. Ignoring num_layers argument")
    basis = init_single_scale_basis(range, num_elements)
  }
  
  basis$cholesky_factors = lapply(FUN = chol,                           basis$covariances)
  basis$inv_sqrt_det =     lapply(FUN = function(M)(1 / prod(diag(M))), basis$cholesky_factors)
  basis$precisions =       lapply(FUN = chol2inv,                       basis$cholesky_factors)
  basis$inner_prods_hh  = matrix(0,  nrow = basis$length, ncol = basis$length) #Called C in the writeup
  basis$inner_prods_hLh = matrix(0,  nrow = basis$length, ncol = basis$length) #Called G in the writeup
  basis$sampler_action  = matrix(NA, nrow = basis$length, ncol = basis$length) #CinvG = MC
  basis$neighbor_mat    = matrix(0,  nrow = basis$length, ncol = basis$length) #Z
  basis$target_coeffs = rep(NA, basis$length)
  basis$par_dim = dimension

    
  get_inner_prod = function(i, j){
    lambda = basis$precisions[[i]] + basis$precisions[[j]]
    nu = solve(lambda, 
               basis$precisions[[i]] %*% basis$means[[i]] + 
               basis$precisions[[j]] %*% basis$means[[j]])
    num = exp(-0.5 * ( - nu * lambda * nu + 
                      t(basis$means[[i]]) %*% basis$precisions[[i]] %*% basis$means[[i]] + 
                      t(basis$means[[j]]) %*% basis$precisions[[j]] %*% basis$means[[j]] ) )
    num = num * basis$inv_sqrt_det[[i]] * basis$inv_sqrt_det[[j]]
    dnm = sqrt(2*pi)^dimension * sqrt(det(lambda))
    return(num / dnm)
  }
  
  #Get inner products
  for(b_in in 1:basis$length){
    for(b_out in 1:basis$length){
      basis$inner_prods_hh[b_in, b_out] = get_inner_prod(b_in, b_out)
    }
  }
  
  # We only estimate traffic between nearby basis elements.
  # This code finds the nearest neighbors for each element.
  basis$neighbors = as.list(rep(0, basis$length))
  for(index in 1:basis$length){
    basis$neighbors[[index]] = order(basis$inner_prods_hh[index, ], 
                                     decreasing = TRUE)[1:num_neighbors]
  }
  #Ensure that neighboring relations are symmetric
  for(b_in in 1:basis$length){
    for(b_out in basis$neighbors[[b_in]]){
      if(! (b_in %in% basis$neighbors[[b_out]]) ){
        basis$neighbors[[b_out]] = c(basis$neighbors[[b_out]], b_in)
      }
    }
  }
  for(index in 1:basis$length){
    basis$neighbor_mat[ basis$neighbors[[index]], index ] = 1
  }
  assertthat::assert_that( all( basis$neighbor_mat == t( basis$neighbor_mat ) ) )

  return(basis)
}

# Return a matrix with `num_samples` columns. Each is a draw from 
# element `index` of `basis`.
get_samples = function(basis, index, num_samples){
  my_chol = basis$cholesky_factors[[index]]
  samples = matrix(rnorm(n = num_samples * basis$par_dim), nrow = basis$par_dim)
  samples = my_chol %*% samples
  for(i in 1:basis$par_dim){
    samples[i,] = samples[i,] + basis$means[[index]][i]
  }
  return(samples)
}

# Accept a matrix with `num_samples` columns. 
# At each, evaluate the density of
# element `index` of `basis`.
get_density = function(points, basis, index){
  nums = rep(NA, dim(points)[2])
  for(j in seq_along(nums)){
    points[ ,j] = points[ ,j] - basis$means[[index]]
    quadratic_j = t(points[ ,j]) %*% basis$precisions[[index]] %*% points[ ,j]
    nums[j] = exp(-0.5 * quadratic_j )
  }
  inv_dnm = basis$inv_sqrt_det[[index]] * ( (2 * pi) ^ ( -basis$par_dim / 2 ) ) 
  densities = nums * inv_dnm
  return(densities)
}

# Accept a matrix with `num_samples` columns. 
# At each, evaluate the estimated density of the target.
target_density_est = function(points, basis){
  densities = rep(0, dim(points)[2])
  for(i in 1:basis$length){
    densities = densities + 
      basis$target_coeffs[[i]] * get_density(points, basis, index = i)
  }
  return(densities)
}

require(ggplot2)
plot_1d_basis = function(basis){
  num_samples = 100
  sampled_df = data.frame(xvals = rep(NA, basis$length*num_samples),
                          yvals = rep(NA, basis$length*num_samples),
                          index = rep(1:basis$length, each = num_samples))
  for(index in 1:basis$length){
    abcissae = matrix(sort(get_samples(basis, index, num_samples)), nrow = 1)
    densities = get_density(abcissae, basis, index)
    sampled_df$xvals[sampled_df$index==index] = abcissae
    sampled_df$yvals[sampled_df$index==index] = densities
  }
  p = ggplot(data = sampled_df) + guides(colour = FALSE) + 
    geom_line(aes(xvals, yvals, colour = as.factor(index)))
  print(p)
}


```

A little bit of testing code. To test the sampler and the density calculations, we should get the same results by histogramming samples and plotting densities.

```{r}
basis = prepare_basis(num_layers = 3)
plot_1d_basis(basis)
samples = get_samples(basis, index = 1, num_samples = 50000)
densities = get_density(samples, basis, index = 1)
hist(samples, probability = TRUE)
my_order = order(samples)
lines(samples[my_order], densities[my_order])
```

The basic algorithm: estimate inner products $\langle h_j, Lh_i \rangle$ where $h_i, h_j$ are masis elements and $L$ is the action of the sampler. Divide out appropriately by $\langle h_j, h_i \rangle$, and get the target as a top eigenvector. The missing entries mean we actually solve a slightly different eigenproblem.

```{r}
require(MASS)
# sampler: a function taking a vector `points_in` of parameter values
#          and returning a vector of outputs from an MH sampler initialized at points_in.
bemc = function(basis, sampler, dimension = 1, NUM_SAMPLES = 10000){

  #Estimate M
  samples_before_mh = matrix(0, ncol = NUM_SAMPLES, nrow = dimension)
  samples_after_mh = matrix(0, ncol = NUM_SAMPLES, nrow = dimension)
  for(b_in in 1:basis$length){
    samples_before_mh = get_samples(basis, b_in, num_samples = NUM_SAMPLES)
    for(b_out in basis$neighbors[[b_in]]){
      samples_after_mh = simple_sampler(points_in = samples_before_mh)
      weights = get_density(points = samples_after_mh, basis, b_out)
      basis$inner_prods_hLh[b_in, b_out] = mean(weights)
    }    
  }
  cinv = ginv(basis$inner_prods_hh, tol = 0.01)
  basis$raw_sampler_action = #Cinv G#
    cinv %*% 
    basis$inner_prods_hLh 
  basis$sampler_action = #Cinv ZGZ#
    cinv %*% 
    basis$neighbor_mat %*% 
    basis$inner_prods_hLh %*%  
    basis$neighbor_mat
  
  basis$target_coeffs = Re(eigen(basis$sampler_action)$vectors[,1])
  basis$target_coeffs = basis$target_coeffs / sum(basis$target_coeffs)
  return(basis)
}
```

####A simple M-H sampler for fodder

This uses MH with a symmetric Gaussian proposal to generate draws from a Gamma(2, 2) target. It tests the results by plotting them against the true density.

```{r}
target = function(x)(dt(x, df = 5))
simple_sampler = function(points_in){
  for(i in 1:8){
    points_out = points_in + rnorm(n = prod(dim(points_in)))
    
    #it's a symmetric proposal, so only the target enters this ratio.
    accepts = rbinom(size = 1, n = dim(points_out)[2], 
                     prob = pmin(1, target(points_out) / target(points_in)))
    points_out[,!accepts] = points_in[,!accepts]
    points_in = points_out
  }
  return(points_out)
}

CHAINLEN = 1e4
x = rep(list(matrix(1, ncol = 1, nrow = 1)), CHAINLEN)
for(i in 2:CHAINLEN){
  x[[i]] = simple_sampler(x[[i-1]])
}
x = as.numeric(x)
hist(x, probability = TRUE, breaks = 50)
lines(sort(x), target(sort(x)))
```

This chunk calls BEMC and plots the results against the ground truth.

```{r, cache = TRUE}
require(gplots)
basis = prepare_basis(dimension = 1, num_elements = 30, num_neighbors = 5)
plot_1d_basis(basis)
image(basis$inner_prods_hh, 
      main = paste("Cond. number:", round(kappa(basis$inner_prods_hh))))
basis = bemc(basis, 
             sampler = simple_sampler, 
             dimension = 1, 
             NUM_SAMPLES = 100)
my_grid = matrix(seq(-5, 5, length.out = 100), ncol = 100)
image(basis$inner_prods_hLh)
image(basis$sampler_action)
plot(my_grid, target(my_grid), type = "l")
lines(my_grid, target_density_est(points = my_grid, basis), col = "red")

```